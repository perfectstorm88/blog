---
layout: post
categories: 机器学习 人工智能
---

### 总结：
- 经典线性回归
- 主成分分析
    - 预测各样本的主成分的值，根据主成分值做线性回归
    - 主成分系数如何转换为原变量的系数
        - 数据公式，计算原理
        - 提取主成分对应的特征向量
        - 数据的标准差
        - 数据的均值
- 线性回归与主成分的区别
    - 相同点都是降维
    - 线性回归是直接选择变量，舍弃某些变量
    - 主成分是根据变量相关关系，可以大幅度降维。
    - 但是也不要迷信主成分，不是万能的，只是提供降维的手段，可能出来的结果对分析更糟糕。
  
### 题目说明
![这里写图片描述](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTUwNzEyMjI1NjIyNzgy)
![这里写图片描述](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTUwNzEyMjI1NjM2NDA1)
### 准备-输入数据
```R
#### 用数据框的形式输入数据
conomy<-data.frame(
  x1=c(149.3, 161.2, 171.5, 175.5, 180.8, 190.7, 
       202.1, 212.4, 226.1, 231.9, 239.0),
  x2=c(4.2, 4.1, 3.1, 3.1, 1.1, 2.2, 2.1, 5.6, 5.0, 5.1, 0.7),
  x3=c(108.1, 114.8, 123.2, 126.9, 132.1, 137.7, 
       146.0, 154.1, 162.3, 164.3, 167.6),
  y=c(15.9, 16.4, 19.0, 19.1, 18.8, 20.4, 22.7, 
      26.5, 28.1, 27.6, 26.3)
)
```

### 作线性回归
```R
#### 作线性回归
lm.sol<-lm(y~x1+x2+x3, data=conomy)
summary(lm.sol)
```
![这里写图片描述](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTUwNzEyMjEzMzQ0NjMz)

从计算结果看，得到的回归方程为：
Y=-10.12799-0.05140X<sub>1</sub>+0.58695<sub>2</sub> +0.28685X<sub>3</sub> 

可以发现这个式子不合理，Y是进口量，X<sub>1</sub>是国内总产值，X<sub>1</sub>的系数为负，说明进口量与国内总产值负相关，不符合实际情况。另外上述公式的显著性校验较低，X<sub>1</sub>一个星都没有。

通过kappa函数进行多重共线性验证，然后根据系数相关性检验，去掉x1
```R
#### 多重共线性验证并重新回归
kappa(cor(conomy[,1:3]),exact=TRUE);
lm.sol<-lm(y~.-x1, data=conomy)
summary(lm.sol)
```
![这里写图片描述](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTUwNzEyMjE0MzEyODM1)

发现截距和系数校验非常好，最终公式为：
Y=-9.742740+ 0.596052<sub>2</sub> +0.212305X<sub>3</sub>

### 主成分回归分析
```R
#### 作主成分分析
conomy.pr<-princomp(~x1+x2+x3, data=conomy, cor=T)
summary(conomy.pr, loadings=TRUE)
```
![这里写图片描述](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTUwNzEyMjIzNzE5ODM4)
前两个主成分已到达99%贡献率，业务含义：
- 第一主成分，关于国内总产值和总消费，产销因子
- 第二主成分，关于存储量，存储因子

预测测样本主成分, 并作主成分分析
```R
pre<-predict(conomy.pr);#预测各样本的主成分的值
conomy$z1<-pre[,1];#主成分1==》z1
conomy$z2<-pre[,2];#主成分2==》z2
lm.sol<-lm(y~z1+z2, data=conomy);#两个主成分z1、z2做自变量，y为因变量，做线性回归
summary(lm.sol);#
```
![这里写图片描述](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTUwNzEyMjI0MjUxMDQ2)
回归系数和回归方程均通过检验，且效果显著，得到回归方程：
Y=21.8909-2.9892Z<sub>2</sub> -0.8288Z<sub>3</sub>

再把上述公式转变为因变量与原变量的关系，根据下列公式
![这里写图片描述](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTUwNzEyMjI0NjU4Mzk0)

作变换, 得到原坐标下的关系表达式
```R
> beta<-coef(lm.sol);#提取回归系数 
> A<-loadings(conomy.pr);#提取主成分对应的特征向量
> x.bar<-conomy.pr$center; #数据中心，即均值
> x.sd<-conomy.pr$scale;#数据标准差
> coef<-(beta[2]*A[,1]+ beta[3]*A[,2])/x.sd ;#计算系数
> beta0 <- beta[1]- sum(x.bar * coef);#截距
> c(beta0, coef)
(Intercept)          x1          x2          x3 
-9.13010782  0.07277981  0.60922012  0.10625939 
```
最终的回归方程为：
Y=-9.13010782 +0.07277981X<sub>1</sub>+0.60922012X<sub>2</sub>+0.10625939 X<sub>3</sub>

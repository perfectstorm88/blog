---
layout: post
categories: JAVA 性能调优 网络
---

本文记录了NIO和AIO的原理、术语、内部运行机制，并对NIO和AIO的应用场景进行了举例

## Java NIO trick and trap 
[http://jm-blog.aliapp.com/?p=536]

### NIO s
区分了Direct ByteBuffer和Heap ByteBuffer
### IO channels
java.nio.channels.SocketChannel
java.nio.channels.ServerSocketChannel
批量数据传输，继承Seletable Channel

### NIO selectors
- 注册Seletable Channel
- SelectionKey —— 表示Selector和被注册的channel 之间关系,一份凭证
- SelectionKey 保存channel感兴趣的事件
- Selector.select 更新所有就绪的SelectionKey的状态,并返回就绪的channel个数
- 迭代Selected Key集合并处理就绪channel

### NIO神话
NIO不一定更快的场景 
 客户端应用
 连接数<1000
 并发程度不高
 局域网环境下

离散的事件驱动模型,编程困难。
碎片化编程
### Reactor模式
核心组件

- Synchronus Event Demultiplexer
- Event loop + 事件分离  Dispatcher
- 事件派发,可以多线程  Request Handler
- 事件处理,业务代码

### 理想的NIO框架
提供良好的codec框架,方便marshall/unmarshall
- A codec is a device or computer program capable of encoding or decoding a digital data stream or signal.[1][2][3] Codec is a portmanteau of coder-decoder or, less commonly, compressor-decompressor.
透明性,内置良好的日志记录和数据统计
### NIO框架性能的关键因素
- 数据的拷贝
- 上下文切换
- 内存管理
- TCP选项、高级IO函数
- 框架设计

#### 减少数据拷贝
关于DirectByteBuffer，“每次创建或者释放的时候 都调用一次System.gc()” 是否可信
HeapByteBuffer，拷贝到临时 DirectByteBuffer,但临 时缓冲区使用缓存。 聚集写/发散读时没有缓 存临时缓冲区。
确切一点：长生命周期,较大的缓冲区适合用Direct
##### View ByteBuffer 
slice()
##### 传输文件
有两个图非常好，传统方式和FileChannel.transferTo方式
拷贝只在kernal，性能有60%左右的提升
##### MappedByteBuffer
将文件映射为内存区域——MappedByteBuffer，适合大文件、只读型操作,如大文件的MD5校验等
#### 减少上下文切换
时间缓存，System.currentTimeMillis， Linux调用gettimeofday,需要切换到内核态
有个测试“1000万次调用需要12秒,平均一次1.3毫秒”，需要确认下

##### Selector.wakeup
 主要作用
 解除阻塞在Selector.select()/select(long)上的线
程,立即返回。
 两次成功的select之间多次调用wakeup等价于一次调 用。
 如果当前没有阻塞在select上,则本次wakeup调用将作 用于下一次select——“记忆”作用。
 为什么要唤醒?
 注册了新的channel或者事件
 channel关闭,取消注册
 优先级更高的事件触发(如定时器事件),希望及时处 理
##### wakeup的原理
Linux上利用pipe调用创建一个管道
Windows上则是一个loopback的tcp连接,这是因为win32的管道无法加入select的fd set
将管道或者TCP连接加入select fd set
wakeup往管道或者连接写入一个字节
阻塞的select因为有IO事件就绪,立即返回
**可见,wakeup的调用开销不可忽视**
##### 减少wakeup调用
仅在有需要的时候才调用
 如往连接发送数据,通常是缓存在一个消息队列,当且仅当 队列为空的注册OP_WRITE并wakeup
 ```java
    boolean needsWakeup=false;
    synchronized(queue)  {
      if(queue.isEmpty())
       needsWakeup=true;
      queue.add(session);
    }
    if(needsWakeup) {
     registerOPWrite();
     selector.wakeup();
    }
```
记录调用状态,避免重复调用
 Netty的优化
```java
AtomicBoolean wakenUp = new AtomicBoolean(); 
wakenUp.set(false); //select之前设置为false selector.select(500);
if (wakenUp.compareAndSet(false, true)) 
{ 
  selector.wakeup();
}
```

##### 读到或者写入0个字节
不代表连接关闭
高负载或者慢速网络下很常见的情况
通常的处理办法是返回并继续注册OP_READ/OP_WRITE等待下 次处理
缺点:系统调用开销,线程切换开销
##### 在当前线程写入
当发送缓冲队列为空的时候,可以直接往channel写数据,而不是放入缓冲队列,interest了OP_WRITE等待IO线 程写入,一定程度上可以提高发送效率。
- 优点:减少系统调用和线程切换
- 缺点:当前线程中断会引起channel关闭
```
if queue.isEmpty
   if writeLock.tryLock &&
  current.compareAndSet(null,msg)
       write to channel
   else
queue.offer(msg); interest OP_WRITE
```

##### 线程模型
的三个主要事件:OP_READ、OP_WRITE和 OP_ACCEPT,都可以运行在不同的线程。
通常Reactor实现为一个线程 ,内部维护一个Selector
```
   while(true){
    int sel=selector.select(timeout);
    processRegister();
    if(sel>0)
processSelected(); }
```
Reactor数目

#### 线程模型的选择
类echo应用,unmashall和业务处理的开销非常低,选 择第一种模型。
 创建线程和切换线程的开销
 第二、第三、第四种模型,从测试来看,OP_ACCEPT的 处理开销很低
 从已经完成三路握手的队列移出  最佳选择:第二种模型
 unmashall一般是cpu-bound
 业务逻辑代码通常比较耗时,不要在reactor线程处理

#### 内存管理
缓冲区的管理
- 池化
- ThreadLocal cache  环形缓冲区
#### Socket缓冲区:SO_RCVBUF和 SO_SNDBUF
Socket.setReceiveBufferSize/setSendBufferSize
对于一次性发送大量数据的应用,增加发送缓冲区到48K、64K可能是唯一的最有效地提 高性能的方式
如果要设置ServerSocket的recv缓冲区超过RFC1323中定义的64k,那么必须在绑定端口 前设置,以后accept产生的socket将继承这一设置

#### Nagle算法:SO_TCPNODELAY 
NAGLE算法通过将缓冲区内的小封包自动相连,组成较大的封包,阻止大量小封包的发送阻塞网络, 从而提高网络应用效率
对于实时性要求较高的应用(telnet、网游),可能需要关闭此算法
##### SO_LINGER选项
Socket. setSoLinger(boolean linger, int timeout)
 控制socket关闭后的行为
 默认行为:linger=false,timeout=-1
 当socket主动close,调用的线程会马上返回,不会阻塞,然后进入CLOSING状态, 残留在缓冲区中的数据将继续发送给对端,并且与对端进行FIN-ACK协议交换,最 后进入TIME_WAIT状态
 Linger=true,timeout>0
 调用close的线程将阻塞,发生两种可能的情况:一是剩余的数据继续发送,进行
关闭协议交换,二就是超时过期,剩余的数据将被删除,进行FIN-ACK交换。 
 Linger=true,timeout=0
 进行所谓“hard-close”,任何剩余的数据都将被丢弃,并且FIN-ACK交换也不会 发生,替代产生RST,让对端抛出"connection reset"的SocketException
##### SSO_KEEPALIVE
 Socket.setKeepAlive(boolean)
 这是TCP层,而非HTTP协议的keep-alive概念
 默认一般为false,用于TCP连接保活,默认间隔2个小时  更建议在应用层做心跳

### 奇淫技巧
#### 发送消息
通常是放入一个缓冲队列注册OP_WRITE等 待IO线程去写
 线程切换、系统调用
 如果队列为空,直接在当前线程channel.write 
 隐患:当前线程的中断会引起连接关闭
### 陷阱
#### 陷阱1:处理事件忘记移除key
在select返回值大于0的情况下,循环处理
Selector.selectedKeys集合,每处理一个必须移除  
```java
Iterator<SelectionKey> it=set.iterator();
While(it.hasNext()){
SelectionKey key=it.next(); it.remove(); //切记移除 „„处理事件
}
```
 不移除的后果是本次的就绪的key集合下次会再次返 回,导致无限循环,CPU消耗 100%
#### 陷阱2:Selector返回的key集合 非线程安全
Selector.selectedKeys/keys 返回的集合都是非线程 安全的
 Selector.selectedKeys返回的可移除 
 Selector.keys 不可变
 对selected keys的处理必须单线程处理或者适当同步
#### 陷阱3:正确注册Channel和更新 interest
直接注册不可吗?
 channel.register(selector, ops, attachment);
不是不可以,效率问题，至少加两次锁,锁竞争激烈
 Channel本身的regLock,竞争几乎没有 
 Selector内部的key集合,竞争激烈
更好的方式:加入缓冲队列,等待注册,reactor单线程处理
注册，如连接请求和读请求
```java
If(isReactorThread()){
    channel.register(selector, ops, attachment);
} else{
   register.offer(new Event(channel,ops,attachment));
selector.wakeup(); }
```
更新 interest
同样,SelectionKey.interest(ops)
 在linux上会阻塞,需要获取selector内部锁做同步 
 在win32上不会阻塞
 屏蔽平台差异,避免锁的激烈竞争,采用类似注册channel的方式:
```java
if (this.isReactorThread()) { 
key.interestOps(key.interestOps() | SelectionKey.OP_READ);
}
else {
      this.register.offer(new Event(key,SelectionKey.OP_READ));
      selector.wakeup();
  }
```
#### 陷阱4:正确处理OP_WRITE
OP_WRITE处理不当很容易导致CPU 100%
OP_WRITE触发条件（前提:interest了OP_WRITE）
- socket发送缓冲区可写  远端关闭
- 有错误发生

 正确的处理方式
- 仅在已经连接的channel上注册
- 仅在有数据可写的时候才注册
- 触发之后立即取消注册,否则会继续触发导致循环 
- 处理完成后视情况决定是否继续注册
-- 没有完全写入,继续注册 
-- 全部写入,无需注册

##### 比较MyCAT的写

```java

	public void doNextWriteCheck() {
		if (!writing.compareAndSet(false, true)) {
			return;
		}
		try {
			boolean noMoreData = write0();
			writing.set(false);
			if (noMoreData && con.writeQueue.isEmpty()) {
				if ((processKey.isValid() && (processKey.interestOps() & SelectionKey.OP_WRITE) != 0)) {
					disableWrite();
				}
			} else {
				if ((processKey.isValid() && (processKey.interestOps() & SelectionKey.OP_WRITE) == 0)) {
					enableWrite(false);
				}
			}
		} catch (IOException e) {
		}
	}
```

1. 先判断是否正在写，如果正在写，退出（之前已经把写内容放到缓冲队列，那么此处可以优化呢，即`当发送缓冲队列为空的时候,可以直接往channel写数据`，理论上可以优化，但是写代码时要注意，因为必需要保证协议包的顺序，还要考虑前一次写时，是否还有buffer没有写完，若前一次写入时，最后一个buffer没有写完，记得退回缓冲队列；）
2. write0()方法是只要buffer中还有，就不停写入；直到写完所有buffer，或者写入时，返回写入字节为零，表示网络繁忙，就回临时退出写操作。
3. 没有完全写入并且缓冲队列为空,取消注册写事件
4. 没有完全写入或者缓冲队列有可写对象,继续注册写事件

##### 比较Cobar的写

**NIOReactor.postWrite()**

这儿传入的参数，不是要写的buffer，而是一个连接对象，只是注册这个对象有内容需要写。要写的buffer，在连接对象自己的缓存队列中
这种方式与MyCAT差不多，连接对象自己维护写队列。

```java

  final void postWrite(NIOConnection c) {
    reactorW.writeQueue.offer(c);
  }

```
**NIOReactor.W内部类**

专门负责缓冲队列写，不停循环遍历，等待其它业务线程放入写数据
```java
  private final class W implements Runnable {
    private final BlockingQueue<NIOConnection> writeQueue;
    private W() {
      this.writeQueue = new LinkedBlockingQueue<NIOConnection>();
    }
    public void run() {
      NIOConnection c = null;
      for (;;) {
        try {
          if ((c = writeQueue.take()) != null) {
             c.writeByQueue();
          }
        } catch (Throwable e) {}
      }
    }
  }

```

**NIOReactor.R内部类,为一个seletor**
同时处理读事件和写事件。但是主要负责的是读，只有在网络非常繁忙等极少数情况下，小概率走到读分支

```java
  private final class R implements Runnable {
    private final Selector selector;
    @Override
    public void run() {
      final Selector selector = this.selector;
      for (;;) {
        try {
          selector.select(1000L);
          register(selector);
          Set<SelectionKey> keys = selector.selectedKeys();
            for (SelectionKey key : keys) {
              Object att = key.attachment();
              if (att != null && key.isValid()) {
                int readyOps = key.readyOps();
                if ((readyOps & SelectionKey.OP_READ) != 0) {
                  read((NIOConnection) att);
                } else if ((readyOps & SelectionKey.OP_WRITE) != 0) {
                   c.writeByEvent();
                } else {
                  key.cancel();
                }
              } else {
                key.cancel();
              }
            }
        } catch (Throwable e) {
        }
      }
    }
  }
```

**基于队列的写和基于事件的写**

队列写：所有的写请求，放到缓存队列，由独立W线程进行写。如果未写完（比如网络繁忙），则注册写事件，然后会再seleltor发现写事件
事件写：R线程中，seletor探测到写事件后，进行写操作。如果写完了，则立即取消注册写事件，避免继续触发导致循环 
总结：主要是W线程进行写，只有在网络繁忙时，才会注册写事件，等待网络写就绪后，R线程就会立即发现写事件，然后R线程再写一部分。


```java
  @Override
  public void writeByQueue() throws IOException {
    if (isClosed.get()) {
      return;
    }
    final ReentrantLock lock = this.writeLock;
    lock.lock();
    try {
      // 满足以下两个条件时，切换到基于事件的写操作。
      // 1.当前key对写事件不该兴趣。
      // 2.write0()返回false。
      if ((processKey.interestOps() & SelectionKey.OP_WRITE) == 0
          && !write0()) {
        enableWrite();
      }
    } finally {
      lock.unlock();
    }
  }

  @Override
  public void writeByEvent() throws IOException {
    if (isClosed.get()) {
      return;
    }
    final ReentrantLock lock = this.writeLock;
    lock.lock();
    try {
      // 满足以下两个条件时，切换到基于队列的写操作。
      // 1.write0()返回true。
      // 2.发送队列的buffer为空。
      if (write0() && writeQueue.size() == 0) {
        disableWrite();
      }
    } finally {
      lock.unlock();
    }
  }
    /**
   * 打开写事件
   */
  private void enableWrite() {
    final Lock lock = this.keyLock;
    lock.lock();
    try {
      SelectionKey key = this.processKey;
      key.interestOps(key.interestOps() | SelectionKey.OP_WRITE);
    } finally {
      lock.unlock();
    }
    processKey.selector().wakeup();
  }

  /**
   * 关闭写事件
   */
  private void disableWrite() {
    final Lock lock = this.keyLock;
    lock.lock();
    try {
      SelectionKey key = this.processKey;
      key.interestOps(key.interestOps() & OP_NOT_WRITE);
    } finally {
      lock.unlock();
    }
  }

```

#####比较MyCAT和Cobar两种写方式

- Cobar的写：业务线程把写请求放到缓冲队列，然后由独立写线程W负责，当W在写的时候，网络慢等原因导致未写完，
 然后注册写事件，由R线程(selector)进行候补写
- MyCAT的写：业务线程先通过加锁或者AtomicBoolean判断当前channel是否正在写数据，如空闲则由当前线程直接写，否则入缓冲队列交给其他线程写；在写的时候，网络慢等原因导致未写完，
 然后注册写事件，由NIOReactor线程(selector)进行候补写；
- MyCAT采用这种方式的优点：尽可能减少系统调用和线程切换


#### 陷阱5:正确取消注册channel
 SelectableChannel一旦注册将一直有效直到明确取消
怎么取消注册?
- channel.close(),内部会调用key.cancel()
- key.cancel();
- 中断 channel的读写所在线程引起的channel关闭
但是这样还不够!
- key.cancel()仅仅是将key加入cancelledKeys   直到下一次select才真正处理
- 并且channel的socketfd只有在真正取消注册后才会 close(fd)
后果是什么?
- 服务端,问题不大,select调用频繁
- 客户端,通常只有一个连接,关闭channel之后,没有调用 select就关闭了selector，sockfd没有关闭,停留在CLOSE_WAIT状态
正确的处理方式,取消注册也应当作为事件交给reactor处理,及时wakeup做select
- 适当的时候调用selector.selectNow()
- Netty在超过256连接关闭的时候主动调用一次 selectNow
```
static final int CLEANUP_INTERVAL = 256;
 private boolean cleanUpCancelledKeys() throws IOException {
         if (cancelledKeys >= CLEANUP_INTERVAL) {
             cancelledKeys = 0;
             selector.selectNow();
             return true;
}
         return false;
     }
//channel关闭的时候 
channel.socket.close(); 
cancelledKeys ++;
```
#### 陷阱6:同时注册OP_ACCPET和OP_READ,同 时注册OP_CONNECT和OP_WRITE
在底层来说,只有两种事件:read和write
 Java NIO还引入了OP_ACCEPT和OP_CONNECT 
 OP_ACCEPT、OP_READ == Read
 OP_CONNECT、OP_WRITE == Write
 同时注册OP_ACCEPT和OP_READ ,或者同时注册 OP_CONNECT和OP_WRITE在不同平台上产生错误的行 为,避免这样做!
**之前碰到，OP_CONNECT和OP_WRITE同时注册，不能主动建立连接**
#### 陷阱7:正确处理connect
在OP_CONNECT触发后,没有移除OP_CONNECT,导致 SelectionKey一直处于就绪状态,空耗CPU
 OP_CONNECT只能在还没有连接的channel上注册
#### 陷阱8:NIO的那些bug，只存在于jdk 6u4
导致已经关闭的连接一直处于就绪状态, select(timeout)不阻塞,CPU消耗100%
在每次channel.close()之后马上调用select
### NIO框架设计
责任链
 Mina: filter chain
 Netty: pipeline
 SEDA架构 
业务处理器 
 回调方法
 业务逻辑碎片化
提供更友好的API
 xSocket,提供同步API,流式API
 方便codec框架,包括常用协议的codec实现
流量控制
统计和监控,透明性
### 基于协程的NIO框架
基于Kilim的HttpClient
### NIO 2.0
Java AIO
 Windows:IOCP
 Linux: epoll模拟 **在linux平台上JAVA AIO比NIO要慢**
http://www.oracle.com/technetwork/articles/java/index.html

[高性能网络服务器编程：为什么linux下epoll是最好，Netty要比NIO.2好？](http://weibo.com/p/2304184c8c58ce0102vkbo?from=page_100505_profile&wvr=6&mod=wenzhangmod)
 epoll在内核通知方式上，也改进了，我们先看select和poll的通知方式，也就是level-triggerednotification，内核在被DMA中断，捕获到IO设备来数据后，本来只需要查找这个数据属于哪个文件描述符，进而通知线程里等待的函数即可，但是，select和poll要求内核在通知阶段还要继续再扫描一次刚才所建立的内核fd和io对应的那个数组，因为应用程序可能没有真正去读上次通知有数据后的那些fd，应用程序上次没读，内核在这次select和poll调用的时候就得继续通知，这个os和应用程序的沟通方式效率是低下的。只是方便编程而已（可以不去读那个网络io，方正下次会继续通知）。

  于是epoll设计了另外一种通知方式：edge-triggerednotification，在这个模式下，io设备来了数据，就只通知这些io设备对应的fd，上次通知过的fd不再通知，内核不再扫描一大堆fd了。

AIO希望的是，你select，poll，epoll都需要用一个函数去监控一大堆fd，那么我AIO不需要了，你把fd告诉内核，你应用程序无需等待，内核会通过信号等软中断告诉应用程序，数据来了，你直接读了，所以，用了AIO可以废弃select，poll，epoll。

但linux的AIO的实现方式是内核和应用共享一片内存区域，应用通过检测这个内存区域（避免调用nonblocking的read、write函数来测试是否来数据，因为即便调用nonblocking的read和write由于进程要切换用户态和内核态，仍旧效率不高）来得知fd是否有数据，可是检测内存区域毕竟不是实时的，你需要在线程里构造一个监控内存的循环，设置sleep，总的效率不如epoll这样的实时通知。所以，AIO是渣，适合低并发的IO操作。所以java7引入的NIO.2引入的AIO对高并发的网络IO设计程序来说，也是渣，只有Netty的epoll+edge-triggerednotification最牛，能在linux让应用和OS取得最高效率的沟通。

## 李林峰的文章
### Netty系列之Netty线程模型
http://www.infoq.com/cn/articles/netty-threading-model#anch112001

## New I/O in JDK 7 
http://openjdk.java.net/projects/nio/
### New File System API
#### Opening/Creating Files
Stream I/O 
### Channels API
NetworkChannel -- channel to network socket
• Defines bind, getLocalAddress, setOption, getOption, methods
Multicasting
### Asynchronous I/O
API
Future style
• Initiate I/O operation, returning java.util.concurrent.Future
• Future interface defines methods to test or wait for completion
Callback style
• Specify CompletionHandler when invoking I/O operation
• CompletionHandler invoked when I/O operation completes (or fails)
####￼ What about Threads?
Who invokes the completion handler? 
- Initiating thread
- Thread in channel group's thread pool
Channel Group
- Encapsulates mechanics required to handle I/O completion 
- Has associated thread pool
- Each asynchronous channel is bound to a group 
-- default group
-- or specify group when creating channel
- Configured by parameters
-- ThreadFactory
-- maximum threads to handle I/O events
### Miscellaneous Updates
Infiniband (IB) Sockets Direct Protocol (SDP) 不懂
Stream Control Transport Protocol (SCTP) 不懂
## 官方文档
http://openjdk.java.net/projects/nio/resources/AsynchronousIo.html
### What happens when an I/O operation completes immediately
会不停出现堆栈，debug时曾看到线程不停堆栈情况。
默认最大16次IO completion。以避免stack overflow和线程饥饿
the maximum number of completion handler frames allowed on a thread stack is configured by a system property where required
### Fixed Thread Pool vs User-supplied/Cached Thread Pool
Fixed Thread pool
http://openjdk.java.net/projects/nio/resources/FixedThreadPool.png
这是比较简单的且性能高的方式，当采用这种方式时，要注意尽量避免在completion handlers中阻塞应用
提交任务到用户定义线程池，仅仅处理completion handle。对于来自kernal的IO和completion evernts则由对应用不可见的1~M个内部线程完成
http://openjdk.java.net/projects/nio/resources/CachedThreadPool.png
当debug代码时，可以看到多了一个线程
Daemon Thread [Thread-0] (Running)	
This configuration delivers good performance despite the hand-off per I/O operation

## Java NIO系列教程（六） Selector
[Selector](http://http://ifeve.com/selectors/)（选择器）是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。
Selector可以监听网络通道的四种不同类型的事件：
- Connect客户端连接服务端事件
- Accept 服务端接收客户端连接事件
- Read   读事件
- Write  写事件
这四种事件用SelectionKey的四个常量来表示：
SelectionKey.OP_CONNECT
SelectionKey.OP_ACCEPT
SelectionKey.OP_READ
SelectionKey.OP_WRITE

不管NIO还是AIO，要处理的网络事件分为下面四种：
- Connect客户端连接服务端事件
- Accept 服务端接收客户端连接事件
- Read   读事件
- Write  写事件

## SelectionKey.channel()  ServerSocketChannel.accept()
selectionKey.channel()方法返回的  channel是ServerSocketChannel还是SocketChannel是由前边注册这个key时是注册channel确定的。
服务器端先注册接收Key
```
serverSocketChannel.register(selector,SelectionKey.OP_ACCEPT)
```

## Reactor vs Proactor
分4各步骤描述了两者的区别
http://www.artima.com/articles/io_design_patterns2.html
Standard/classic Reactor:

Step 1) wait for event (Reactor job)
Step 2) dispatch "Ready-to-Read" event to user handler ( Reactor job)
Step 3) read data (user handler job)
Step 4) process data ( user handler job)
Proposed emulated Proactor:

Step 1) wait for event (Proactor job)
Step 2) read data (now Proactor job)
Step 3) dispatch "Read-Completed" event to user handler (Proactor job)
Step 4) process data (user handler job)

![Proactor与其它模式的关系图](http://www.yeolar.com/media/note/2012/12/10/proactor/fig9.png)
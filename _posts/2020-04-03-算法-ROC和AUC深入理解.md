---
layout: post
categories: 算法
---


对于分类器，或者说分类算法，评价指标主要有precision，recall，F-score等，以及这里要讨论的ROC和AUC。

ROC (Receiver Operating Characteristic) 曲线和 AUC (Area Under the Curve) 值常被用来评价一个二值分类器 (binary classifier)

# 看一个ROC的例子
![ROC曲线的示例](https://pic4.zhimg.com/80/v2-7be243979fcc5fb6b8f7b97f29275fe7_1440w.jpg)

横坐标：1-Specificity，伪正类率(False positive rate， FPR)，预测为正但实际为负的样本占所有负例样本的比例；

纵坐标：Sensitivity，真正类率(True positive rate， TPR)，预测为正且实际为正的样本占所有正例样本的比例。

在一个二分类模型中，假设采用逻辑回归分类器，其给出针对每个实例为正类的概率，那么通过设定一个阈值如0.6，概率大于等于0.6的为正类，小于0.6的为负类。对应的就可以算出一组(FPR,TPR)，在平面中得到对应坐标点。随着阈值的逐渐减小，越来越多的实例被划分为正类，但是这些正类中同样也掺杂着真正的负实例，即TPR和FPR会同时增大。阈值最大时，对应坐标点为(0,0)，阈值最小时，对应坐标点(1,1)。

横轴FPR：1-TNR，1-Specificity，FPR越大，预测正类中实际负类越多。
纵轴TPR：Sensitivity(正类覆盖率)，TPR越大，预测正类中实际正类越多。
理想目标：TPR=1，FPR=0，即图中(0,1)点，故ROC曲线越靠拢(0,1)点，越偏离45度对角线越好，Sensitivity、Specificity越大效果越好。
随着阈值threshold调整，ROC坐标系里的点如何移动可以参考：
![](https://pic4.zhimg.com/80/v2-7be243979fcc5fb6b8f7b97f29275fe7_1440w.jpg)

为何叫ROC这么奇怪的名字：
ROC曲线：接收者操作特征曲线（receiver operating characteristic curve）（https://en.wikipedia.org/wiki/Receiver_operating_characteristic），是反映敏感性和特异性连续变量的综合指标，roc曲线上每个点 **反映着对同一信号刺激的感受性**。

# 如何画ROC曲线
## 方法1：调用 metrics.roc_curve进行计算
参考: https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python

```
# sklearn中的ROC曲线  https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html
from sklearn import metrics
year_str=str(df.year.max())
y = df2.GXB
# df.loc[df2['5.0']>1,'5.0']=1
scores = df2[year_str]
fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=1)
# print(fpr, tpr, thresholds)
plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange',
         lw=lw, label='ROC curve' )
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()
```
## 方法2：自己计算
参考: 
```
y = df2.GXB.to_numpy()
score = df2[year_str].to_numpy()
# false positive rate
fpr = []
# true positive rate
tpr = []
# Iterate thresholds from 0.0, 0.01, ... 1.0
thresholds = np.arange(0.0, 1.01, .02)

# get number of positive and negative examples in the dataset
P = sum(y)
N = len(y) - P

# iterate through all thresholds and determine fraction of true positives
# and false positives found at this threshold
for thresh in thresholds:
    FP=0
    TP=0
    for i in range(len(score)):
        if (score[i] > thresh):
            if y[i] == 1:
                TP = TP + 1
            if y[i] == 0:
                FP = FP + 1
    fpr.append(FP/float(N))
    tpr.append(TP/float(P))
```

## 方法3：使用plot_metric
```python
# https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python
# # plot_metric 这个库介绍了一种画法，但是threshold需要自己制定，并不能自动计算个最大值
from plot_metric.functions import BinaryClassification
# Visualisation with plot_metric
bc = BinaryClassification(y, score, labels=["Class 1", "Class 2"])

# Figures
plt.figure(figsize=(5,5))
bc.plot_roc_curve(threshold=0.23)
plt.show()
plt.close()
```
# 参考
- [机器学习之分类性能度量指标 : ROC曲线、AUC值、正确率、召回率](https://zhuanlan.zhihu.com/p/31256633)